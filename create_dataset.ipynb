{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5df2b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9165 training examples\n",
      "Sample name: ['it', 'is', 'cold']\n",
      "Sample palette: [(86, 131, 192), (151, 221, 209), (128, 109, 212), (160, 208, 218), (191, 167, 229)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from colormath.color_conversions import convert_color\n",
    "from colormath.color_objects import sRGBColor, LabColor\n",
    "from colormath.color_diff import delta_e_cie2000\n",
    "\n",
    "# Patch for numpy.asscalar removed in newer versions\n",
    "def patch_asscalar(a):\n",
    "    return a.item()\n",
    "\n",
    "setattr(np, \"asscalar\", patch_asscalar)\n",
    "\n",
    "# Load training data\n",
    "with open(\"hexcolor_vf/train_names.pkl\", \"rb\") as f:\n",
    "    train_names = pickle.load(f)\n",
    "    \n",
    "with open(\"hexcolor_vf/train_palettes_rgb.pkl\", \"rb\") as f:\n",
    "    train_palettes_rgb = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(train_names)} training examples\")\n",
    "print(f\"Sample name: {train_names[0]}\")\n",
    "print(f\"Sample palette: {train_palettes_rgb[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd805ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original count: 9165\n",
      "After deduplication: 7752\n",
      "Duplicates removed: 1413\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate training data - keep only first occurrence of duplicate strings\n",
    "seen_names = {}\n",
    "unique_names = []\n",
    "unique_palettes = []\n",
    "\n",
    "for name_tokens, palette in zip(train_names, train_palettes_rgb):\n",
    "    # Convert name tokens to string\n",
    "    name_str = \" \".join(name_tokens) if isinstance(name_tokens, list) else name_tokens\n",
    "    \n",
    "    # Only add if we haven't seen this name before\n",
    "    if name_str not in seen_names:\n",
    "        seen_names[name_str] = True\n",
    "        unique_names.append(name_tokens)\n",
    "        unique_palettes.append(palette)\n",
    "\n",
    "print(f\"Original count: {len(train_names)}\")\n",
    "print(f\"After deduplication: {len(unique_names)}\")\n",
    "print(f\"Duplicates removed: {len(train_names) - len(unique_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f69a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB examples (for RAG): 6252\n",
      "Query examples (for JSONL): 1500\n"
     ]
    }
   ],
   "source": [
    "# Split into DB examples (for RAG) and query examples (1500 for JSONL)\n",
    "# We'll use the last 1500 unique examples as our query examples\n",
    "# The rest will go into the DB for RAG retrieval\n",
    "\n",
    "QUERY_SIZE = 1500\n",
    "\n",
    "if len(unique_names) < QUERY_SIZE:\n",
    "    raise ValueError(f\"Not enough unique examples! Have {len(unique_names)}, need at least {QUERY_SIZE}\")\n",
    "\n",
    "# Split: everything except last 1500 goes to DB, last 1500 are query examples\n",
    "db_names = unique_names[:-QUERY_SIZE]\n",
    "db_palettes = unique_palettes[:-QUERY_SIZE]\n",
    "\n",
    "query_names = unique_names[-QUERY_SIZE:]\n",
    "query_palettes = unique_palettes[-QUERY_SIZE:]\n",
    "\n",
    "print(f\"DB examples (for RAG): {len(db_names)}\")\n",
    "print(f\"Query examples (for JSONL): {len(query_names)}\")\n",
    "assert len(query_names) == QUERY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e11d1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ChromaDB for training RAG...\n",
      "Deleted existing collection\n",
      "Created new collection\n"
     ]
    }
   ],
   "source": [
    "# Helper function to convert RGB to hex\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
    "\n",
    "# Create ChromaDB collection with DB examples (not the query examples)\n",
    "CHROMA_PATH = \"chroma_db_train\"\n",
    "COLLECTION_NAME = \"train_rag\"\n",
    "MODEL_NAME = \"all-mpnet-base-v2\"\n",
    "\n",
    "print(\"Initializing ChromaDB for training RAG...\")\n",
    "client = chromadb.PersistentClient(path=CHROMA_PATH)\n",
    "\n",
    "# Create embedding function\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=MODEL_NAME)\n",
    "\n",
    "# Delete collection if it exists, then create fresh\n",
    "try:\n",
    "    client.delete_collection(name=COLLECTION_NAME)\n",
    "    print(\"Deleted existing collection\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = client.create_collection(name=COLLECTION_NAME, embedding_function=ef)\n",
    "print(\"Created new collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6a0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating ChromaDB with training examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6252/6252 [00:21<00:00, 295.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database creation complete. Total items in DB: 6252\n"
     ]
    }
   ],
   "source": [
    "# Populate ChromaDB with DB examples\n",
    "print(\"Populating ChromaDB with training examples...\")\n",
    "batch_size = 128\n",
    "\n",
    "documents = []\n",
    "ids = []\n",
    "\n",
    "for idx, (name_tokens, palette_rgb) in enumerate(tqdm(zip(db_names, db_palettes), total=len(db_names))):\n",
    "    try:\n",
    "        desc = \" \".join(name_tokens) if isinstance(name_tokens, list) else name_tokens\n",
    "        if not desc or not palette_rgb or len(palette_rgb) != 5:\n",
    "            continue\n",
    "        \n",
    "        # Convert palette to hex\n",
    "        hex_palette = [rgb_to_hex(rgb) for rgb in palette_rgb]\n",
    "        \n",
    "        # Create document structure similar to query_db.py format\n",
    "        doc_structure = {\n",
    "            \"description\": desc,\n",
    "            \"palette\": hex_palette\n",
    "        }\n",
    "        \n",
    "        documents.append(json.dumps(doc_structure))\n",
    "        ids.append(f\"db_{idx}\")\n",
    "        \n",
    "        # Batch insert\n",
    "        if len(documents) >= batch_size:\n",
    "            descriptions = [json.loads(d)[\"description\"] for d in documents]\n",
    "            batch_embeddings = ef(descriptions)\n",
    "            collection.add(ids=ids, embeddings=batch_embeddings, documents=documents)\n",
    "            documents.clear()\n",
    "            ids.clear()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing DB entry {idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Add remaining documents\n",
    "if documents:\n",
    "    descriptions = [json.loads(d)[\"description\"] for d in documents]\n",
    "    batch_embeddings = ef(descriptions)\n",
    "    collection.add(ids=ids, embeddings=batch_embeddings, documents=documents)\n",
    "\n",
    "print(f\"Database creation complete. Total items in DB: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca201249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test palette: ['#efd1b3', '#ceaa96', '#9b6162', '#99705b', '#a87c6f']\n",
      "Test diversity: 18.63\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate palette diversity (from ml/grader/grader.py)\n",
    "def calculate_palette_diversity(palette_rgb):\n",
    "    \"\"\"\n",
    "    Calculate diversity of a color palette using pairwise CIELAB color distances.\n",
    "    \n",
    "    Args:\n",
    "        palette_rgb: List of RGB tuples [(r1,g1,b1), (r2,g2,b2), ...]\n",
    "    \n",
    "    Returns:\n",
    "        float: Average pairwise distance between colors\n",
    "    \"\"\"\n",
    "    # Convert RGB to LAB color objects\n",
    "    lab_colors = []\n",
    "    for rgb in palette_rgb:\n",
    "        # Create sRGB color object (values should be 0-255)\n",
    "        rgb_color = sRGBColor(rgb[0], rgb[1], rgb[2], is_upscaled=True)\n",
    "        # Convert to LAB\n",
    "        lab_color = convert_color(rgb_color, LabColor)\n",
    "        lab_colors.append(lab_color)\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    pairwise_distance = 0.0\n",
    "    num_pairs = 0\n",
    "    N = len(lab_colors)\n",
    "    \n",
    "    for i in range(N - 1):\n",
    "        cur_color = lab_colors[i]\n",
    "        for j in range(i + 1, N):\n",
    "            distance = delta_e_cie2000(cur_color, lab_colors[j])\n",
    "            pairwise_distance += distance\n",
    "            num_pairs += 1\n",
    "    \n",
    "    return pairwise_distance / num_pairs if num_pairs > 0 else 0.0\n",
    "\n",
    "# Test the function\n",
    "test_palette = query_palettes[0]\n",
    "test_diversity = calculate_palette_diversity(test_palette)\n",
    "print(f\"Test palette: {[rgb_to_hex(rgb) for rgb in test_palette]}\")\n",
    "print(f\"Test diversity: {test_diversity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8a875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts defined\n"
     ]
    }
   ],
   "source": [
    "# Define prompts (from ml/evaluator/config.py)\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert Color Theorist and UI Designer. Your task is to generate a cohesive, aesthetically pleasing color palette based on a user's text query.\n",
    "\n",
    "Generate a JSON response with the following format:\n",
    "{\n",
    "    \"palette_text\": [\"color_name1\", \"color_name2\", \"color_name3\", \"color_name4\", \"color_name5\"],\n",
    "    \"palette_hex\": [\"#XXXXXX\", \"#XXXXXX\", \"#XXXXXX\", \"#XXXXXX\", \"#XXXXXX\"]\n",
    "}\n",
    "\n",
    "\\\\no_think\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "What's the best color palette consisting of five colors to describe the text {query}?\n",
    "Provide the color values using text (hex) format in ascending order.\n",
    "\n",
    "Here are some associate text-palette pairs for reference:\n",
    "### REFERENCE PALETTES\n",
    "{examples}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Prompts defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8744b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating JSONL dataset with 1500 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [01:28<00:00, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL dataset saved to train_dataset.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate JSONL dataset\n",
    "output_file = \"train_dataset.jsonl\"\n",
    "\n",
    "print(f\"Generating JSONL dataset with {len(query_names)} examples...\")\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for idx, (name_tokens, palette_rgb) in enumerate(tqdm(zip(query_names, query_palettes), total=len(query_names))):\n",
    "        try:\n",
    "            # Get query string\n",
    "            query_str = \" \".join(name_tokens) if isinstance(name_tokens, list) else name_tokens\n",
    "            \n",
    "            if not query_str or not palette_rgb or len(palette_rgb) != 5:\n",
    "                print(f\"Skipping invalid entry at index {idx}\")\n",
    "                continue\n",
    "            \n",
    "            # Retrieve RAG examples from DB (similar to query_db.py)\n",
    "            results = collection.query(\n",
    "                query_texts=[query_str],\n",
    "                n_results=3\n",
    "            )\n",
    "            \n",
    "            # Format examples\n",
    "            examples_str = \"\"\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                for i, result_doc in enumerate(results['documents'][0], start=1):\n",
    "                    data = json.loads(result_doc)\n",
    "                    examples_str += f\"Palette {i}:\\n\"\n",
    "                    examples_str += f\"Description: {data['description']}\\n\"\n",
    "                    for color in data['palette']:\n",
    "                        examples_str += f\"  - {color}\\n\"\n",
    "                    examples_str += \"\\n\"\n",
    "            \n",
    "            # Create full query with system prompt + user prompt\n",
    "            user_prompt = USER_PROMPT_TEMPLATE.format(query=query_str, examples=examples_str)\n",
    "            full_query = SYSTEM_PROMPT + \"\\n\" + user_prompt\n",
    "            \n",
    "            # Convert palette to hex\n",
    "            gt_palette_hex = [rgb_to_hex(rgb) for rgb in palette_rgb]\n",
    "            \n",
    "            # Calculate diversity\n",
    "            gt_diversity = calculate_palette_diversity(palette_rgb)\n",
    "            \n",
    "            # Create JSONL entry\n",
    "            entry = {\n",
    "                \"input\": {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"assistant\", \"content\": full_query}\n",
    "                    ],\n",
    "                    \"gt_palette\": gt_palette_hex,\n",
    "                    \"gt_diversity\": gt_diversity\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Write to file\n",
    "            f.write(json.dumps(entry) + \"\\n\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query entry {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "print(f\"JSONL dataset saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a6627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying JSONL output format:\n",
      "================================================================================\n",
      "\n",
      "Total lines in JSONL: 1500\n",
      "\n",
      "================================================================================\n",
      "FIRST EXAMPLE:\n",
      "================================================================================\n",
      "Query preview (first 200 chars): \n",
      "You are an expert Color Theorist and UI Designer. Your task is to generate a cohesive, aesthetically pleasing color palette based on a user's text query.\n",
      "\n",
      "Generate a JSON response with the following ...\n",
      "\n",
      "Ground truth palette: ['#efd1b3', '#ceaa96', '#9b6162', '#99705b', '#a87c6f']\n",
      "Ground truth diversity: 18.63\n",
      "\n",
      "================================================================================\n",
      "FULL STRUCTURE OF FIRST ENTRY:\n",
      "================================================================================\n",
      "{\n",
      "  \"input\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\nYou are an expert Color Theorist and UI Designer. Your task is to generate a cohesive, aesthetically pleasing color palette based on a user's text query.\\n\\nGenerate a JSON response with the following format:\\n{\\n    \\\"palette_text\\\": [\\\"color_name1\\\", \\\"color_name2\\\", \\\"color_name3\\\", \\\"color_name4\\\", \\\"color_name5\\\"],\\n    \\\"palette_hex\\\": [\\\"#XXXXXX\\\", \\\"#XXXXXX\\\", \\\"#XXXXXX\\\", \\\"#XXXXXX\\\", \\\"#XXXXXX\\\"]\\n}\\n\\n\\\\no_think\\n\\n\\nWhat's the best color palette consisting of five colors to describe the text iced coffee?\\nProvide the color values using text (hex) format in ascending order.\\n\\nHere are some associate text-palette pairs for reference:\\n### REFERENCE PALETTES\\nPalette 1:\\nDescription: hot coffee\\n  - #b2945a\\n  - #98642f\\n  - #eca600\\n  - #ec4700\\n  - #fff96a\\n\\nPalette 2:\\nDescription: coffee\\n  - #592403\\n  - #792e08\\n  - #db976d\\n  - #b1683b\\n  - #411905\\n\\nPalette 3:\\nDescription: a...\n"
     ]
    }
   ],
   "source": [
    "# Verify the output by reading a few lines\n",
    "print(\"Verifying JSONL output format:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "with open(output_file, \"r\") as f:\n",
    "    # Count lines\n",
    "    lines = f.readlines()\n",
    "    print(f\"\\nTotal lines in JSONL: {len(lines)}\")\n",
    "    \n",
    "    # Show first example\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FIRST EXAMPLE:\")\n",
    "    print(\"=\" * 80)\n",
    "    first_entry = json.loads(lines[0])\n",
    "    print(f\"Query preview (first 200 chars): {first_entry['input']['messages'][0]['content'][:200]}...\")\n",
    "    print(f\"\\nGround truth palette: {first_entry['input']['gt_palette']}\")\n",
    "    print(f\"Ground truth diversity: {first_entry['input']['gt_diversity']:.2f}\")\n",
    "    \n",
    "    # Show structure\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FULL STRUCTURE OF FIRST ENTRY:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(json.dumps(first_entry, indent=2)[:1000] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
